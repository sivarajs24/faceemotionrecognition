# ğŸ­ Facial Emotion Recognition System

A real-time facial emotion recognition system using deep learning (CNN) with a professional web interface. Detects and classifies 7 human emotions from live webcam feeds.

## âœ¨ Features

- **Real-time Emotion Detection**: Live webcam-based emotion classification
- **7 Emotion Classes**: Angry, Disgust, Fear, Happy, Neutral, Sad, Surprise
- **Web-Based Interface**: Professional UI with gradient design and live statistics
- **Multi-Face Detection**: Detect emotions on multiple faces simultaneously
- **Live Analytics Dashboard**: Real-time emotion distribution with percentages
- **Camera Controls**: Start/Stop/Screenshot buttons for user control
- **Advanced CNN Model**: 5.2M parameters with BatchNormalization for stability
- **Prediction Smoothing**: 5-frame buffer to reduce false positives
- **Preprocessing Pipeline**: Histogram equalization and Gaussian blur for robustness

## ğŸ—ï¸ Project Structure

```
faceemotionrecognition/
â”œâ”€â”€ app.py                      # Flask web application
â”œâ”€â”€ config.py                   # Configuration & hyperparameters
â”œâ”€â”€ model.py                    # CNN architecture
â”œâ”€â”€ train.py                    # Training script
â”œâ”€â”€ detect.py                   # Desktop detection (optional)
â”œâ”€â”€ utils.py                    # Utility functions
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ .gitignore                 # Git ignore patterns
â”œâ”€â”€ haarcascade_frontalface_default.xml  # Face detector
â”œâ”€â”€ model_file_30epochs.h5     # Trained model
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html             # Web interface
â””â”€â”€ data/
    â”œâ”€â”€ train/                 # Training images
    â”‚   â”œâ”€â”€ angry/
    â”‚   â”œâ”€â”€ disgust/
    â”‚   â”œâ”€â”€ fear/
    â”‚   â”œâ”€â”€ happy/
    â”‚   â”œâ”€â”€ neutral/
    â”‚   â”œâ”€â”€ sad/
    â”‚   â””â”€â”€ surprise/
    â””â”€â”€ test/                  # Test images
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Webcam (for real-time detection)
- 500MB disk space

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/sivarajs24/faceemotionrecognition.git
cd faceemotionrecognition
```

2. **Create virtual environment** (optional but recommended)
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

### Running the Application

#### Web-Based Emotion Recognition (Recommended)
```bash
python app.py
```
Then open your browser and go to: **http://localhost:5000**

**Features:**
- Click **Start** to begin emotion detection
- Watch live emotion labels and confidence scores
- Real-time statistics update every 2 seconds
- Click **Stop** to pause detection
- **Screenshot** button to capture current frame
- **Reset** button to clear statistics

#### Desktop Detection (Real-time)
```bash
python detect.py
```
Press `q` to quit the application.

#### Training the Model
```bash
python train.py
```
Customize training parameters in `config.py`:
- `EPOCHS`: Number of training epochs
- `BATCH_SIZE`: Batch size for training
- `LEARNING_RATE`: Learning rate for optimizer

## ğŸ“Š Model Architecture

**CNN with 5.2M Parameters:**
- **Block 1**: Conv2D(32) â†’ Conv2D(64) â†’ MaxPool â†’ Dropout
- **Block 2**: Conv2D(128) â†’ MaxPool â†’ Dropout
- **Block 3**: Conv2D(256) â†’ MaxPool â†’ Dropout
- **Fully Connected**: Dense(512) â†’ Dense(256) â†’ Dense(7)
- **Normalization**: BatchNormalization after each Conv2D layer

**Training Details:**
- Dataset: 35,000+ facial images
- Image Size: 48Ã—48 grayscale
- Optimizer: Adam with learning rate decay
- Loss Function: Categorical crossentropy
- Validation Split: 20%

## ğŸ› ï¸ Technical Stack

| Component | Technology |
|-----------|-----------|
| **Backend** | Flask 3.1.2 |
| **Deep Learning** | TensorFlow 2.x, Keras |
| **Computer Vision** | OpenCV (cv2) |
| **Data Processing** | NumPy, Pillow |
| **Frontend** | HTML5, CSS3, JavaScript |
| **Visualization** | Matplotlib |
| **Version Control** | Git |

## ğŸ“ˆ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Web interface |
| `/video_feed` | GET | MJPEG video stream |
| `/stats` | GET | Emotion statistics (JSON) |
| `/start_camera` | GET | Activate camera |
| `/stop_camera` | GET | Pause camera |
| `/reset_stats` | GET | Reset statistics |
| `/camera_status` | GET | Get camera status |

## ğŸ“¸ Screenshots

The web interface features:
- Live video feed with emotion labels
- Real-time statistics panel
- Animated emotion distribution bars
- Professional gradient design
- Responsive layout for all devices

## ğŸ§  How It Works

1. **Face Detection**: Haar Cascade Classifier detects faces in video stream
2. **Preprocessing**: 
   - Grayscale conversion
   - Histogram equalization for better contrast
   - Gaussian blur for noise reduction
3. **Emotion Prediction**: CNN model predicts emotion probability
4. **Smoothing**: 5-frame buffer averages predictions
5. **Display**: Emotion label and confidence score shown on face
6. **Statistics**: Emotion counts and percentages tracked in real-time

## ğŸ¯ Performance

- **Inference Speed**: ~20-30 FPS on CPU
- **Model Size**: 20MB (H5 format)
- **Face Detection Accuracy**: High with preprocessing
- **Emotion Classification**: Optimized for 7 classes

## ğŸ“š Configuration

Edit `config.py` to customize:

```python
# Model
IMG_HEIGHT = 48
IMG_WIDTH = 48
EPOCHS = 30
BATCH_SIZE = 32

# Face Detection
SCALE_FACTOR = 1.1
MIN_NEIGHBORS = 5
MIN_FACE_SIZE = (50, 50)

# Emotion Classes
EMOTION_LABELS = {
    0: 'Angry', 1: 'Disgust', 2: 'Fear',
    3: 'Happy', 4: 'Neutral', 5: 'Sad', 6: 'Surprise'
}
```

## ğŸ”§ Troubleshooting

**Camera not found:**
- Ensure webcam permissions are granted
- Check camera is not in use by another application

**Low FPS:**
- Reduce frame resolution in `config.py`
- Close unnecessary applications

**Inaccurate detections:**
- Ensure adequate lighting
- Move closer to camera
- Update model with more training data

## ğŸ“ Dataset Structure

```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ angry/       (4,000+ images)
â”‚   â”œâ”€â”€ disgust/     (4,000+ images)
â”‚   â”œâ”€â”€ fear/        (4,000+ images)
â”‚   â”œâ”€â”€ happy/       (5,000+ images)
â”‚   â”œâ”€â”€ neutral/     (5,000+ images)
â”‚   â”œâ”€â”€ sad/         (5,000+ images)
â”‚   â””â”€â”€ surprise/    (4,000+ images)
â””â”€â”€ test/
    â””â”€â”€ (Similar structure with validation images)
```

## ğŸ“„ Requirements

```
tensorflow>=2.13.0
keras>=2.13.0
opencv-python>=4.8.0
numpy>=1.23.0
flask>=3.1.2
pillow>=10.0.0
matplotlib>=3.8.0
```

## ğŸš€ Future Enhancements

- [ ] Multi-person emotion tracking with unique IDs
- [ ] Emotion timeline visualization
- [ ] Cloud deployment (AWS/Google Cloud)
- [ ] Mobile app integration
- [ ] Real-time audio emotion detection
- [ ] Emotion intensity measurement
- [ ] Cross-cultural emotion models
- [ ] API for third-party integration

## ğŸ“– Learning Resources

- [TensorFlow Documentation](https://www.tensorflow.org/learn)
- [OpenCV Face Detection](https://docs.opencv.org/master/db/d28/tutorial_cascade_classifier.html)
- [Flask Web Development](https://flask.palletsprojects.com/)
- [CNN Architecture Guide](https://en.wikipedia.org/wiki/Convolutional_neural_network)

## ğŸ“ License

This project is open source and available under the MIT License.

## ğŸ‘¨â€ğŸ’» Author

**Sivaraj S**
- GitHub: [@sivarajs24](https://github.com/sivarajs24)
- Email: harishsiva242005@gmail.com

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## â­ Support

If you find this project useful, please consider giving it a star! â­

---

**Last Updated**: December 2025
**Version**: 1.0.0
